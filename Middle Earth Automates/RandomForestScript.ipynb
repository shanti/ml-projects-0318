{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditCustomers = pd.read_csv(\"../data/project/ds.csv\")\n",
    "#creditCustomers\n",
    "\n",
    "creditcustomers_small = creditCustomers.iloc[:,1:]\n",
    "creditcustomers_small = creditcustomers_small.rename(columns={'FICO V2 Score':'F02_SCORE',  'FICO V3 Score':'F03_SCORE', 'FICO V08 Score':'F08_SCORE'})\n",
    "creditcustomers_small = creditcustomers_small.loc[creditcustomers_small['F02_SCORE'] < 1000]\n",
    "\n",
    "#Removing customers with credit score > 800 and declined\n",
    "creditcustomers_small = creditcustomers_small.loc[(creditcustomers_small['F02_SCORE'] < 800) \n",
    "                | ((creditcustomers_small['F02_SCORE'] >= 800) & (creditcustomers_small['Status'] == 'APPROVED'))]\n",
    "creditcustomers_small = creditcustomers_small.loc[(creditcustomers_small['F03_SCORE'] < 800) \n",
    "                | ((creditcustomers_small['F03_SCORE'] >= 800) & (creditcustomers_small['Status'] == 'APPROVED'))]\n",
    "creditcustomers_small = creditcustomers_small.loc[(creditcustomers_small['F08_SCORE'] < 800) \n",
    "                | ((creditcustomers_small['F08_SCORE'] >= 800) & (creditcustomers_small['Status'] == 'APPROVED'))]\n",
    "\n",
    "#No need to run the below as all that have score > 1000 have the same value for all columns\n",
    "#creditcustomers_small = creditcustomers_small.loc[creditcustomers_small['F03_SCORE'] < 1000]\n",
    "#creditcustomers_small = creditcustomers_small.loc[creditcustomers_small['F08_SCORE'] < 1000]\n",
    "\n",
    "#creditcustomers_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing status APPROVED to 1\n",
    "creditcustomers_small.replace(to_replace={'Status':\"APPROVED\"}, value=1, inplace=True)\n",
    "#Replacing status DECLINED to 0\n",
    "creditcustomers_small.replace(to_replace={'Status':\"DECLINED\"}, value=0, inplace=True)\n",
    "\n",
    "#creditcustomers_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = creditcustomers_small[['F02_SCORE', 'F03_SCORE', 'F08_SCORE']].values\n",
    "labels = creditcustomers_small['Status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set count  395\n",
      "testing set count  170\n"
     ]
    }
   ],
   "source": [
    " from sklearn.model_selection import train_test_split\n",
    "## Split into training and test\n",
    "## TODO: create training and test with an 80/20 split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(fv, labels, test_size=0.3)\n",
    "\n",
    "\n",
    "print (\"training set count \", len(X_train))\n",
    "print (\"testing set count \", len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set count:  395 / 70%\n",
      "Testing set count:  170 / 30%\n",
      "Accuracy = 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Training set count: \", len(X_train), \"/ 70%\")\n",
    "print (\"Testing set count: \", len(Y_test), \"/ 30%\")\n",
    "print(\"Accuracy = \" + str(accuracy_score(Y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6828837734783223"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
